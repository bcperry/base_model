{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # importing OS in order to make GPU visible\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# specify which device you want to work on.\n",
    "# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # importyng sys in order to access scripts located in a different folder\n",
    "\n",
    "path2scripts = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\research\\\\' \n",
    "sys.path.insert(0, path2scripts) # making scripts in models/research available for import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the TF .record files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = r'C:\\Users\\bcper\\Documents\\GitHub\\xView_data_utilities'\n",
    "image_path = r'C:\\Users\\bcper\\Desktop\\Dataset\\train_images' + '\\\\'\n",
    "\n",
    "#small image set for testing\n",
    "#image_path = r'C:\\Users\\bcper\\Desktop\\images' + '\\\\'\n",
    "\n",
    "\n",
    "geojson_name = r'\\train_data_clean.geojson'\n",
    "geojson_path = r'C:\\Users\\bcper\\Desktop\\Dataset' + geojson_name\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "#name to be appended to the .record files\n",
    "filename = 'Cleaned'\n",
    "\n",
    "test_ratio = .2\n",
    "\n",
    "\n",
    "%run process_wv.py $image_path $geojson_path -s=$filename -t=$test_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filenames and locations\n",
    "class_label_filename = 'Class Labels.txt'\n",
    "class_label_path = r'C:\\Users\\bcper\\Documents\\GitHub\\model_training' + '\\\\' + class_label_filename\n",
    "\n",
    "label_map_name = 'label_map.pbtxt'\n",
    "label_map_path = r'C:\\Users\\bcper\\Desktop\\Dataset' + '\\\\' + label_map_name\n",
    "\n",
    "\n",
    "\n",
    "#read in the class labels\n",
    "class_dict = {}\n",
    "file = open(class_label_path, \"r\")\n",
    "\n",
    "#create a class label dictionary\n",
    "for line in file:\n",
    "    key, value = line.split(':')\n",
    "    class_dict[int(key)] = value.strip()\n",
    "\n",
    "\n",
    "#this will make the list in the correct label format for tensorflow\n",
    "x = ''\n",
    "for key in class_dict:\n",
    "    x = x + ('item { \\n\\tid: ' + str(key) + '\\n\\tname: \\\"' + class_dict.get(key) + '\\\"\\n}\\n\\n')\n",
    "    \n",
    "# Write the label map to a file\n",
    "#lmap = open(label_map_path,\"w\")#write mode\n",
    "#lmap.write(x)\n",
    "#lmap.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the .config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_pipeline(pipeline):\n",
    "\n",
    "    # fine_tune_checkpoint\n",
    "    pipeline = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(checkpoint), pipeline)\n",
    " \n",
    "    # tfrecord files train and test.\n",
    "    pipeline = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record), pipeline)\n",
    "    pipeline = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record), pipeline)\n",
    "\n",
    "    # label_map_path\n",
    "    pipeline = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map), pipeline)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    pipeline = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch), pipeline)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    pipeline = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(steps), pipeline)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    pipeline = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(classes), pipeline)\n",
    "    #f.write(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be the model directory of the cloned tensorflow git repo\n",
    "wd = r'C:/Users/bcper/Documents/GitHub/models'\n",
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "model_name = 'ssd_resnet152_v1_fpn_640x640'\n",
    "pretrained_model_dir = 'ssd_resnet152_v1_fpn_640x640_coco17_tpu-8'\n",
    "model_version = 'v3'\n",
    "\n",
    "config_source = r'/models/' + model_name + '/' + model_version + '/vbig/pipeline.config'\n",
    "config_destination = r'/' + model_name + '/' + model_version + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bcper\\\\Documents\\\\GitHub\\\\models\\\\workspace\\\\pre-trained_models\\\\ssd_resnet152_v1_fpn_640x640\\\\ckpt-0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline file\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "bad escape \\U at position 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                     \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mESCAPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\U'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-05e132ff7e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_outpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Overwriting pipeline file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0medit_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_outpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-4fba5c724be4>\u001b[0m in \u001b[0;36medit_pipeline\u001b[1;34m(pipeline)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# fine_tune_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     pipeline = re.sub('fine_tune_checkpoint: \".*?\"',\n\u001b[0m\u001b[0;32m      5\u001b[0m                'fine_tune_checkpoint: \"{}\"'.format(checkpoint), pipeline)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# internal: compile replacement pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m                 \u001b[0mlappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\U at position 25"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "classes = 60\n",
    "steps = 10000\n",
    "batch = 6\n",
    "\n",
    "pipeline_inpath = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\pre-trained_models' + '\\\\' + pretrained_model_dir + '\\pipeline.config'\n",
    "pipeline_outpath = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\models' + '\\\\' + model_name + '\\\\' + model_version + '\\pipeline.config'\n",
    "\n",
    "data_dir_path = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\data'\n",
    "\n",
    "test_record = data_dir_path + r'\\xview_test_Cleaned.record'\n",
    "train_record = data_dir_path + r'\\xview_train_Cleaned.record'\n",
    "label_map = data_dir_path + r'\\label_map.pbtxt'\n",
    "checkpoint = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\pre-trained_models' + '\\\\' + model_name + '\\\\ckpt-0'\n",
    "\n",
    "\n",
    "with open(pipeline_inpath) as file:\n",
    "    pipeline = file.read()\n",
    "    \n",
    "#print(pipeline)\n",
    "     \n",
    "if os.path.exists(pipeline_outpath):\n",
    "    with open(pipeline_outpath, 'w') as f:\n",
    "        print('Overwriting pipeline file')\n",
    "        edit_pipeline(pipeline)\n",
    "else:\n",
    "    with open(pipeline_outpath, 'x') as f:\n",
    "        print('Creating pipeline file')\n",
    "        edit_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be the model directory of the cloned tensorflow git repo\n",
    "wd = r'C:/Users/bcper/Documents/GitHub/models'\n",
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "model_name = 'ssd_resnet152_v1_fpn_640x640'\n",
    "model_version = 'v2'\n",
    "\n",
    "\n",
    "\n",
    "config_path = r'/models/' + model_name + '/' + model_version + '/vbig/pipeline.config'\n",
    "model_path = r'/' + model_name + '/' + model_version + '/'\n",
    "config_path = work_path + r'/models/'+ model_name + '/' + model_version + '/pipeline.config'\n",
    "model_path = work_path + r'/models/'+ model_name + '/' + model_version + '/' \n",
    "train_steps = 2000\n",
    "eval_steps = 1\n",
    "\n",
    "\n",
    "#run the model training\n",
    "work_path = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "#this fails to train for some reason\n",
    "#!python model_main_tf2.py --pipeline_config_path=$config_path --model_dir=$model_path --alsologtostderr \n",
    "cmd_string = r'python model_main_tf2.py --pipeline_config_path=' + config_path + r' --model_dir=' + model_path + r' --alsologtostderr'\n",
    "\n",
    "print(cmd_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "path = r'\\models\\resnet50'\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "tensorboard_path = os.getcwd() + path\n",
    "\n",
    "\n",
    "!tensorboard --logdir=$tensorboard_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 15:54:37.384699 10592 deprecation.py:596] From C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0607 15:54:40.814950 10592 convolutional_keras_box_predictor.py:153] depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 15:54:46.423235 10592 deprecation.py:330] From C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x000001EF9DF3BEE0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 15:55:09.459595 10592 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.faster_rcnn_meta_arch.FasterRCNNMetaArch object at 0x000001EF9DF3BEE0>, because it is not built.\n",
      "W0607 15:55:34.251533 10592 save.py:238] Found untraced functions such as FirstStageBoxPredictor_layer_call_and_return_conditional_losses, FirstStageBoxPredictor_layer_call_fn, mask_rcnn_keras_box_predictor_layer_call_and_return_conditional_losses, mask_rcnn_keras_box_predictor_layer_call_fn, FirstStageBoxPredictor_layer_call_fn while saving (showing 5 of 70). These functions will not be directly callable after loading.\n",
      "C:\\Users\\bcper\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0607 15:55:46.700710 10592 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace/exported_models/resnet50_racoon_v1\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0607 15:55:48.545793 10592 builder_impl.py:774] Assets written to: C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace/exported_models/resnet50_racoon_v1\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing pipeline config file to C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace/exported_models/resnet50_racoon_v1\\pipeline.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0607 15:55:54.708206 10592 config_util.py:253] Writing pipeline config file to C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace/exported_models/resnet50_racoon_v1\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "model_name = 'resnet50_racoon'\n",
    "model_version = 'v1'\n",
    "\n",
    "\n",
    "pipeline_config_path = os.getcwd() + r'/models/'+ model_name + '/' + model_version + '/pipeline.config'\n",
    "trained_checkpoint_dir=os.getcwd() + r'/models/' + model_name + '/' + model_version\n",
    "output_directory=os.getcwd() + r'/exported_models/'+ model_name + '_' + model_version\n",
    "\n",
    "\n",
    "\n",
    "%run exporter_main_v2.py --pipeline_config_path=$pipeline_config_path --trained_checkpoint_dir=$trained_checkpoint_dir --output_directory=$output_directory --input_type=image_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "7c618cd5-39ec-46c6-bee7-0cfe5297f22a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
