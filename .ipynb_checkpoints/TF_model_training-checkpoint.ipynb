{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # importing OS in order to make GPU visible\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# specify which device you want to work on.\n",
    "# Use \"-1\" to work on a CPU. Default value \"0\" stands for the 1st GPU that will be used\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # importyng sys in order to access scripts located in a different folder\n",
    "\n",
    "path2scripts = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\research\\\\' \n",
    "sys.path.insert(0, path2scripts) # making scripts in models/research available for import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the TF .record files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = r'C:\\Users\\bcper\\Documents\\GitHub\\xView_data_utilities'\n",
    "image_path = r'C:\\Users\\bcper\\Desktop\\Dataset\\train_images' + '\\\\'\n",
    "\n",
    "#small image set for testing\n",
    "#image_path = r'C:\\Users\\bcper\\Desktop\\images' + '\\\\'\n",
    "\n",
    "\n",
    "geojson_name = r'\\train_data_clean.geojson'\n",
    "geojson_path = r'C:\\Users\\bcper\\Desktop\\Dataset' + geojson_name\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "#name to be appended to the .record files\n",
    "filename = 'Cleaned'\n",
    "\n",
    "test_ratio = .2\n",
    "\n",
    "\n",
    "%run process_wv.py $image_path $geojson_path -s=$filename -t=$test_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filenames and locations\n",
    "class_label_filename = 'Class Labels.txt'\n",
    "class_label_path = r'C:\\Users\\bcper\\Documents\\GitHub\\model_training' + '\\\\' + class_label_filename\n",
    "\n",
    "label_map_name = 'label_map.pbtxt'\n",
    "label_map_path = r'C:\\Users\\bcper\\Desktop\\Dataset' + '\\\\' + label_map_name\n",
    "\n",
    "\n",
    "\n",
    "#read in the class labels\n",
    "class_dict = {}\n",
    "file = open(class_label_path, \"r\")\n",
    "\n",
    "#create a class label dictionary\n",
    "for line in file:\n",
    "    key, value = line.split(':')\n",
    "    class_dict[int(key)] = value.strip()\n",
    "\n",
    "\n",
    "#this will make the list in the correct label format for tensorflow\n",
    "x = ''\n",
    "for key in class_dict:\n",
    "    x = x + ('item { \\n\\tid: ' + str(key) + '\\n\\tname: \\\"' + class_dict.get(key) + '\\\"\\n}\\n\\n')\n",
    "    \n",
    "# Write the label map to a file\n",
    "#lmap = open(label_map_path,\"w\")#write mode\n",
    "#lmap.write(x)\n",
    "#lmap.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the .config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_pipeline(pipeline):\n",
    "\n",
    "    # fine_tune_checkpoint\n",
    "    pipeline = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(checkpoint), pipeline)\n",
    " \n",
    "    # tfrecord files train and test.\n",
    "    pipeline = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record), pipeline)\n",
    "    pipeline = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record), pipeline)\n",
    "\n",
    "    # label_map_path\n",
    "    pipeline = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map), pipeline)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    pipeline = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch), pipeline)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    pipeline = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(steps), pipeline)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    pipeline = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(classes), pipeline)\n",
    "    #f.write(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be the model directory of the cloned tensorflow git repo\n",
    "wd = r'C:/Users/bcper/Documents/GitHub/models'\n",
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "model_name = 'ssd_resnet152_v1_fpn_640x640'\n",
    "pretrained_model_dir = 'ssd_resnet152_v1_fpn_640x640_coco17_tpu-8'\n",
    "model_version = 'v3'\n",
    "\n",
    "config_source = r'/models/' + model_name + '/' + model_version + '/vbig/pipeline.config'\n",
    "config_destination = r'/' + model_name + '/' + model_version + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline file\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "bad escape \\U at position 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                     \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mESCAPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\\\U'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-05e132ff7e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_outpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Overwriting pipeline file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0medit_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_outpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-4fba5c724be4>\u001b[0m in \u001b[0;36medit_pipeline\u001b[1;34m(pipeline)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# fine_tune_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     pipeline = re.sub('fine_tune_checkpoint: \".*?\"',\n\u001b[0m\u001b[0;32m      5\u001b[0m                'fine_tune_checkpoint: \"{}\"'.format(checkpoint), pipeline)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# internal: compile replacement pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, state)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m                 \u001b[0mlappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\U at position 25"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "classes = 60\n",
    "steps = 10000\n",
    "batch = 6\n",
    "\n",
    "pipeline_inpath = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\pre-trained_models' + '\\\\' + pretrained_model_dir + '\\pipeline.config'\n",
    "pipeline_outpath = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\models' + '\\\\' + model_name + '\\\\' + model_version + '\\pipeline.config'\n",
    "\n",
    "data_dir_path = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\data'\n",
    "\n",
    "test_record = data_dir_path + r'\\xview_test_Cleaned.record'\n",
    "train_record = data_dir_path + r'\\xview_train_Cleaned.record'\n",
    "label_map = data_dir_path + r'\\label_map.pbtxt'\n",
    "checkpoint = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace\\pre-trained_models' + '\\\\' + model_name + '\\\\ckpt-0'\n",
    "\n",
    "\n",
    "with open(pipeline_inpath) as file:\n",
    "    pipeline = file.read()\n",
    "    \n",
    "#print(pipeline)\n",
    "     \n",
    "if os.path.exists(pipeline_outpath):\n",
    "    with open(pipeline_outpath, 'w') as f:\n",
    "        print('Overwriting pipeline file')\n",
    "        edit_pipeline(pipeline)\n",
    "else:\n",
    "    with open(pipeline_outpath, 'x') as f:\n",
    "        print('Creating pipeline file')\n",
    "        edit_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should be the model directory of the cloned tensorflow git repo\n",
    "wd = r'C:/Users/bcper/Documents/GitHub/models'\n",
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "model_name = 'ssd_resnet152_v1_fpn_640x640'\n",
    "model_version = 'v2'\n",
    "\n",
    "\n",
    "\n",
    "config_path = r'/models/' + model_name + '/' + model_version + '/vbig/pipeline.config'\n",
    "model_path = r'/' + model_name + '/' + model_version + '/'\n",
    "config_path = work_path + r'/models/'+ model_name + '/' + model_version + '/pipeline.config'\n",
    "model_path = work_path + r'/models/'+ model_name + '/' + model_version + '/' \n",
    "train_steps = 2000\n",
    "eval_steps = 1\n",
    "\n",
    "\n",
    "#run the model training\n",
    "work_path = r'C:\\Users\\bcper\\Documents\\GitHub\\models\\workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "#this fails to train for some reason\n",
    "!python model_main_tf2.py --pipeline_config_path=$config_path --model_dir=$model_path --alsologtostderr \n",
    "cmd_string = r'python model_main_tf2.py --pipeline_config_path=' + config_path + r' --model_dir=' + model_path + r' --alsologtostderr'\n",
    "\n",
    "print(cmd_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "path = r'\\models\\resnet50'\n",
    "\n",
    "os.chdir(work_path)\n",
    "\n",
    "tensorboard_path = os.getcwd() + path\n",
    "\n",
    "\n",
    "!tensorboard --logdir=$tensorboard_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "work_path = r'C:/Users/bcper/Documents/GitHub/models/workspace'\n",
    "os.chdir(work_path)\n",
    "\n",
    "\n",
    "pipeline_config_path = os.getcwd() + r'/models/'+ model_name + '/' + model_version + '/pipeline.config'\n",
    "trained_checkpoint_dir=os.getcwd() + r'/models/' + model_name + '/' + model_version\n",
    "output_directory=os.getcwd() + r'/exported_models/'+ model_name + '_' + model_version\n",
    "\n",
    "\n",
    "\n",
    "%run exporter_main_v2.py --pipeline_config_path=$pipeline_config_path --trained_checkpoint_dir=$trained_checkpoint_dir --output_directory=$output_directory --input_type=image_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "7c618cd5-39ec-46c6-bee7-0cfe5297f22a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
